{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HoangHungLN/MachineLearning_Assignment/blob/main/Extended_Assignment/notebooks/Extended_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Phần mở rộng – Học tham số HMM (Hidden Markov Model)**\n",
        "\n",
        "Trong phần mở rộng của lớp **Kỹ sư Tài năng**, nhóm em chọn chủ đề **Hidden Markov Model (HMM)**  và áp dụng vào bài toán **Gán nhãn Từ loại (POS Tagging)**.\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Dữ liệu và tiền xử lý**\n",
        "\n",
        "Nhóm sử dụng **tập dữ liệu POS Tagging** (đã gán nhãn sẵn) từ Kaggle.  \n",
        "Dữ liệu được chia thành hai phần: **train.json** và **dev.json**.\n",
        "\n",
        "Các bước xử lý chính:\n",
        "\n",
        "- Đọc dữ liệu từ file JSON và tách thành các cặp **(X, Y)** tương ứng với  \n",
        "  câu (chuỗi từ) và chuỗi nhãn POS.  \n",
        "- Xây dựng **vocabulary** và **tag set**:  \n",
        "  - Loại bỏ các từ xuất hiện ít (min_freq = 1).  \n",
        "  - Thêm token đặc biệt `<UNK>` để xử lý từ chưa từng gặp (OOV).  \n",
        "- Tạo ánh xạ giữa từ/nhãn và chỉ số: `word2id`, `tag2id`, `id2tag`.  \n",
        "- Thay thế các từ ngoài từ điển bằng `<UNK>` trong tập train và dev.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Huấn luyện mô hình HMM**\n",
        "\n",
        "Nhóm hiện thực hàm `estimate_hmm_supervised()` để học 3 tham số chính của HMM:\n",
        "\n",
        "λ = (π, A, B)\n",
        "\n",
        "- **π (pi):** Xác suất nhãn xuất hiện ở vị trí đầu tiên của câu.  \n",
        "- **A:** Ma trận xác suất chuyển tiếp giữa các nhãn,  \n",
        "  A<sub>ij</sub> = P(tag<sub>j</sub> | tag<sub>i</sub>)  \n",
        "- **B:** Ma trận xác suất phát xạ,  \n",
        "  B<sub>jk</sub> = P(word<sub>k</sub> | tag<sub>j</sub>)\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Cách tính tham số**\n",
        "\n",
        "- **Làm mịn Laplace (Laplace Smoothing):**  \n",
        "  Khởi tạo các ma trận đếm `pi_cnt`, `A_cnt`, `B_cnt` với giá trị nhỏ (alpha) để tránh xác suất 0.  \n",
        "- **Đếm tần suất:**  \n",
        "  - `pi_cnt`: Đếm nhãn đầu tiên của mỗi câu.  \n",
        "  - `A_cnt`: Đếm số lần chuyển tiếp giữa hai nhãn liên tiếp.  \n",
        "  - `B_cnt`: Đếm số lần một nhãn phát ra một từ.  \n",
        "- **Chuẩn hóa:**  \n",
        "  Chia mỗi hàng của ma trận đếm cho tổng hàng để thu được xác suất:\n",
        "\n",
        "  π = pi_cnt / sum(pi_cnt)  \n",
        "  A<sub>ij</sub> = A_cnt[i, j] / sum(A_cnt[i, :])  \n",
        "  B<sub>ij</sub> = B_cnt[i, j] / sum(B_cnt[i, :])\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Kết quả**\n",
        "\n",
        "Sau khi huấn luyện, nhóm thu được ba ma trận **π**, **A**, **B**, đại diện cho mô hình HMM hoàn chỉnh.  \n",
        "Các tham số này sẽ được sử dụng cho phần **Viterbi** (tìm chuỗi nhãn tốt nhất)  \n",
        "và **Forward** (tính xác suất quan sát) trong các bước kế tiếp của bài mở rộng.\n"
      ],
      "metadata": {
        "id": "fmkTlLuup2jQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dRutvNf1zS0l",
        "outputId": "60491f81-d33d-43df-c8d7-b6091b87e759"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-30 01:00:18--  https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Extended_Assignment/data/train.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27164412 (26M) [text/plain]\n",
            "Saving to: ‘data/train.json’\n",
            "\n",
            "data/train.json     100%[===================>]  25.91M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-11-30 01:00:19 (335 MB/s) - ‘data/train.json’ saved [27164412/27164412]\n",
            "\n",
            "--2025-11-30 01:00:19--  https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Extended_Assignment/data/dev.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3915073 (3.7M) [text/plain]\n",
            "Saving to: ‘data/dev.json’\n",
            "\n",
            "data/dev.json       100%[===================>]   3.73M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-11-30 01:00:19 (140 MB/s) - ‘data/dev.json’ saved [3915073/3915073]\n",
            "\n",
            "--2025-11-30 01:00:19--  https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Extended_Assignment/modules/forward_algorithm.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1230 (1.2K) [text/plain]\n",
            "Saving to: ‘modules/forward_algorithm.py’\n",
            "\n",
            "modules/forward_alg 100%[===================>]   1.20K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-11-30 01:00:19 (78.4 MB/s) - ‘modules/forward_algorithm.py’ saved [1230/1230]\n",
            "\n",
            "--2025-11-30 01:00:19--  https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Extended_Assignment/modules/viterbi_algorithm.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2713 (2.6K) [text/plain]\n",
            "Saving to: ‘modules/viterbi_algorithm.py’\n",
            "\n",
            "modules/viterbi_alg 100%[===================>]   2.65K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-11-30 01:00:20 (61.0 MB/s) - ‘modules/viterbi_algorithm.py’ saved [2713/2713]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import getpass, os, subprocess, textwrap\n",
        "\n",
        "# Tạo thư mục và tải dữ liệu train/dev, cùng các module HMM\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "os.makedirs(\"modules\", exist_ok=True)\n",
        "!wget https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Extended_Assignment/data/train.json -O data/train.json\n",
        "!wget https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Extended_Assignment/data/dev.json -O data/dev.json\n",
        "!wget https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Extended_Assignment/modules/forward_algorithm.py -O modules/forward_algorithm.py\n",
        "!wget https://raw.githubusercontent.com/HoangHungLN/MachineLearning_Assignment/refs/heads/main/Extended_Assignment/modules/viterbi_algorithm.py -O modules/viterbi_algorithm.py\n",
        "\n",
        "DATA_FILE = \"data/train.json\"\n",
        "DEV_FILE = \"data/dev.json\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mf7OF_xtpyIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Đọc dữ liệu JSON thô từ file\n",
        "with open(DATA_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_train = json.load(f)\n",
        "with open(DEV_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_dev = json.load(f)\n",
        "\n",
        "# Tách dữ liệu thành các cặp câu (X) và nhãn (Y)\n",
        "X_train = [ex[\"sentence\"] for ex in raw_train]\n",
        "Y_train = [ex[\"labels\"] for ex in raw_train]\n",
        "X_dev = [ex[\"sentence\"] for ex in raw_dev]\n",
        "Y_dev = [ex[\"labels\"] for ex in raw_dev]"
      ],
      "metadata": {
        "id": "vfN130uH_WTx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "UNK = \"<UNK>\"\n",
        "min_freq = 1\n",
        "\n",
        "# Đếm tần suất từ, xây dựng từ điển `vocab` (chỉ giữ từ > min_freq)\n",
        "word_freq = Counter(w for sent in X_train for w in sent)\n",
        "vocab = [w for w, c in word_freq.items() if c > min_freq]\n",
        "vocab.append(UNK)\n",
        "vocab = sorted(vocab)\n",
        "\n",
        "# Tạo tập nhãn `tag_set` duy nhất\n",
        "tag_set = sorted(list(set(t for tags in Y_train for t in tags)))\n",
        "\n",
        "# Tạo ánh xạ từ/nhãn sang ID và ngược lại\n",
        "word2id = {w: i for i, w in enumerate(vocab)}\n",
        "tag2id = {t: i for i, t in enumerate(tag_set)}\n",
        "id2tag = {i: t for t, i in tag2id.items()}\n",
        "\n",
        "# Hàm thay thế các từ hiếm/không biết (Out-of-Vocabulary) bằng token `UNK`\n",
        "def map_unk(sent):\n",
        "    return [w if w in word2id else UNK for w in sent]\n",
        "\n",
        "# Ánh xạ `UNK` cho tập train/dev\n",
        "X_train = [map_unk(s) for s in X_train]\n",
        "X_dev = [map_unk(s) for s in X_dev]"
      ],
      "metadata": {
        "id": "t_VNNWm4_rJb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hàm ước lượng tham số HMM (pi, A, B) từ dữ liệu có giám sát\n",
        "def estimate_hmm_supervised(X, Y, tag2id, word2id, alpha_pi=1.0, alpha_A=1.0, alpha_B=1e-3):\n",
        "    K, V = len(tag2id), len(word2id)\n",
        "\n",
        "    # Khởi tạo ma trận đếm (count) với làm mịn Laplace (alpha)\n",
        "    pi_cnt = np.full(K, alpha_pi, dtype=np.float64)  # Đếm P(tag bắt đầu)\n",
        "    A_cnt = np.full((K, K), alpha_A, dtype=np.float64) # Đếm P(tag_j | tag_i)\n",
        "    B_cnt = np.full((K, V), alpha_B, dtype=np.float64) # Đếm P(word | tag)\n",
        "\n",
        "    # Duyệt qua từng câu và nhãn trong tập huấn luyện để đếm\n",
        "    for words, tags in zip(X, Y):\n",
        "        if not words:\n",
        "            continue\n",
        "\n",
        "        # 1. Đếm xác suất ban đầu (pi)\n",
        "        pi_cnt[tag2id[tags[0]]] += 1\n",
        "\n",
        "        for t in range(len(words)):\n",
        "            j = tag2id[tags[t]]\n",
        "            w = word2id[words[t]]\n",
        "            # 2. Đếm xác suất phát xạ (B)\n",
        "            B_cnt[j, w] += 1\n",
        "\n",
        "            if t < len(words) - 1:\n",
        "                i = tag2id[tags[t]]\n",
        "                k = tag2id[tags[t+1]]\n",
        "                # 3. Đếm xác suất chuyển tiếp (A)\n",
        "                A_cnt[i, k] += 1\n",
        "\n",
        "    # Chuẩn hóa các ma trận đếm để ra ma trận xác suất\n",
        "    pi = pi_cnt / pi_cnt.sum()\n",
        "    A = A_cnt / A_cnt.sum(axis=1, keepdims=True)\n",
        "    B = B_cnt / B_cnt.sum(axis=1, keepdims=True)\n",
        "\n",
        "    return pi, A, B\n",
        "\n",
        "# Gọi hàm để huấn luyện và lấy các tham số HMM\n",
        "pi, A, B = estimate_hmm_supervised(X_train, Y_train, tag2id, word2id)"
      ],
      "metadata": {
        "id": "Lh4UDXq9_7cA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Giải thuật Forward\n"
      ],
      "metadata": {
        "id": "Yo3dXv1nDnN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from modules.forward_algorithm import *\n",
        "idx_unk = word2id[UNK]\n",
        "results = []\n",
        "for sentence_words in X_dev:\n",
        "    # Bỏ qua câu rỗng (nếu có)\n",
        "    if not sentence_words:\n",
        "        continue\n",
        "\n",
        "    # Chuyển câu sang chuỗi quan sát O (indices)\n",
        "    O_indices = []\n",
        "    for word in sentence_words:\n",
        "        idx = word2id.get(word, idx_unk)\n",
        "        O_indices.append(idx)\n",
        "    O_indices = np.array(O_indices)\n",
        "\n",
        "    prob = forward_algorithm(O_indices, pi, A, B)\n",
        "\n",
        "    results.append( (' '.join(sentence_words), prob) )\n",
        "\n",
        "results.sort(key=lambda x: x[1])\n",
        "\n",
        "print(f\"\\n--- KẾT QUẢ THÍ NGHIỆM FORWARD (trên {len(results)} câu của dev.json) ---\")\n",
        "\n",
        "print(f\"\\n--- 10 CÂU CÓ XÁC SUẤT THẤP NHẤT ---\")\n",
        "# Lấy 10 câu đầu tiên (thấp nhất)\n",
        "for sentence, p in results[:10]:\n",
        "  print(f\"Prob: {p: .2e} | Câu: {sentence}\")\n",
        "\n",
        "print(f\"\\n--- 10 CÂU CÓ XÁC SUẤT CAO NHẤT ---\")\n",
        "# Lấy 10 câu cuối (cao nhất) và lật ngược lại\n",
        "for sentence, p in reversed(results[-10:]):\n",
        "  print(f\"Prob: {p: .2e} | Câu: {sentence}\")"
      ],
      "metadata": {
        "id": "lUcPLRSGIBVa",
        "outputId": "be81b990-725e-4403-f3fe-1e9a2a7b4bfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- KẾT QUẢ THÍ NGHIỆM FORWARD (trên 5527 câu của dev.json) ---\n",
            "\n",
            "--- 10 CÂU CÓ XÁC SUẤT THẤP NHẤT ---\n",
            "Prob:  1.41e-246 | Câu: <UNK> <UNK> <UNK> , San Francisco , telecommunications holding company , annual sales of $ 9.5 billion , no damage to headquarters , but no power , the power failure has caused a delay in the release of the company 's earnings report , major concern is subsidiaries , Pacific Bell and Pacific Telesis Cellular , both of which sustained damage to buildings , structural damage to several cellular sites in Santa Cruz , volume of calls on cellular phones 10 times the usual , causing a big slowdown .\n",
            "Prob:  3.93e-243 | Câu: Daniel von <UNK> is <UNK> but totally assured as Major Battle , <UNK> just the right brand of <UNK> and <UNK> ; Jeff Weiss is fire , <UNK> and <UNK> <UNK> as the <UNK> senator who serves as a friendly <UNK> of Major Battle ; <UNK> <UNK> is <UNK> <UNK> playing a succession of lawyers ; Joseph Daly has the perfect `` <UNK> , <UNK> '' <UNK> of George Bush in his portrayal of the vice president ; and Ann McDonough is <UNK> as a succession of witnesses ' wives .\n",
            "Prob:  8.83e-243 | Câu: <UNK> <UNK> & <UNK> <UNK> , San Francisco , electric , gas and water supplier , annual sales $ 7.6 billion , some minor damage to headquarters , <UNK> damage to four nearby <UNK> , severe structural damage to a major power plant at Moss <UNK> , extensive damage to gas lines and electric lines , 400,000 <UNK> without electricity and <UNK> without gas , can not <UNK> electricity until it is certain there are no gas leaks , no predictions on when this will happen .\n",
            "Prob:  1.63e-218 | Câu: If , for example , in the midst of a great social occasion ( such as an international conference on revising the <UNK> Treaty in <UNK> ) , one 's <UNK> father , himself a great <UNK> once , should happen to die of a stroke , one must continue to serve the port : `` Please do n't think me unduly improper in not ascending to see my father in his deceased condition just at this moment .\n",
            "Prob:  1.73e-215 | Câu: As he stands on a hill at the beginning of a six-day motor <UNK> from <UNK> to <UNK> , where a former <UNK> <UNK> , perhaps the victim of an unhappy 20-year marriage , perhaps ( he hopes with more <UNK> than he will ever acknowledge ) not <UNK> to return to domestic service , Stevens surveys the view and thereby provides a <UNK> , a <UNK> and the author 's metaphor for the aesthetic of the novel we 're reading :\n",
            "Prob:  5.91e-215 | Câu: But we still hear him <UNK> at night because the Navy has a few ships left , and to satisfy him the Navy 's sea lift forces were given to a new Air Force bureaucracy in Illinois , its space operations to another command in Colorado , the <UNK> to a new Army bureaucracy in Fort <UNK> , and the Navy 's Indian Ocean and Persian Gulf forces to an Army bureaucracy in Florida .\n",
            "Prob:  3.47e-211 | Câu: Mr. <UNK> , a former publisher and real estate developer , has put together an $ 8 million financial package that includes approximately $ 4 million of tax exempt bonds issued by the State of Illinois ( the first time that a state has used its educational facilities authority to support construction of a theater ) , and approximately $ 1 million in grants from the National <UNK> for the Arts , the <UNK> Foundation , and a few other deep pockets .\n",
            "Prob:  3.61e-208 | Câu: The $ 4 billion in bonds break down as follows : $ 1 billion in five-year bonds with a coupon rate of 8.25 % and a yield to maturity of 8.33 % ; $ 1 billion in 10-year bonds with a coupon rate of 8.375 % and a yield to maturity of 8.42 % ; $ 2 billion in 30-year bonds with five-year call protection , a coupon rate of 8.75 % and a yield to maturity of <UNK> % .\n",
            "Prob:  2.10e-196 | Câu: Thus , you do the public a great <UNK> when Mr. <UNK> suggests , even <UNK> , that the Clean Water Act prohibits the preparation of a scotch and water ; your <UNK> readers may be led to believe that nothing but chance or oversight protects them , as they <UNK> in the night with their scotch and waters , from the <UNK> knock of the Sierra Club at their doors .\n",
            "Prob:  5.27e-196 | Câu: In an <UNK> of little <UNK> to his central point about private enforcement suits by environmental groups , Michael S. <UNK> <UNK> your readers , `` ... the Clean Water Act is written upon the presumption -- the <UNK> , rather -- that nothing but zero risk will do ; it establishes a legal standard of zero discharge '' ( `` <UNK> Environmental <UNK> , '' Sept. 18 ) .\n",
            "\n",
            "--- 10 CÂU CÓ XÁC SUẤT CAO NHẤT ---\n",
            "Prob:  1.10e-03 | Câu: <UNK> .\n",
            "Prob:  1.10e-03 | Câu: <UNK> .\n",
            "Prob:  4.70e-04 | Câu: <UNK> <UNK>\n",
            "Prob:  7.24e-05 | Câu: Citicorp\n",
            "Prob:  3.98e-05 | Câu: <UNK> :\n",
            "Prob:  3.98e-05 | Câu: <UNK> :\n",
            "Prob:  3.98e-05 | Câu: <UNK> :\n",
            "Prob:  3.98e-05 | Câu: <UNK> :\n",
            "Prob:  9.17e-06 | Câu: White <UNK>\n",
            "Prob:  9.17e-06 | Câu: White <UNK>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phân tích và Đánh giá Kết quả Giải thuật Forward\n",
        "\n",
        "## 1. Các câu có xác suất cao nhất\n",
        "\n",
        "10 câu có xác suất cao nhất đều là các câu cực kỳ ngắn (1-2 từ).Đáng chú ý nhất, các câu có xác suất cao tuyệt đối là \"UNK .\" và \"UNK UNK\".\n",
        "\n",
        "Từ kết quả ta có thể thấy được hiện tượng thiên vị về độ dài. Cụ thể, các câu càng ngắn thì càng có xác suất lớn. Hiện tượng trên là do giải thuật Forward tính xác suất cuối cùng P(O) bằng cách nhân liên tiếp các xác suất tại mỗi bước thời gian.Vì tất cả các xác suất đều nhỏ hơn 1.0, về mặt toán học, câu càng ngắn thì càng ít phép nhân dẫn xác suất cuối cùng càng cao.\n",
        "\n",
        "Bên cạnh đó, sự xuất hiện của UNK, UNK trở thành từ phổ biến nhất trong từ điển do quá trình thay thế từ hiếm với sự xuất hiện ít hơn 2 lần thành UNK, quá trình đó cộng dồn trong quá trình train tham số cho mô hình, dẫn đến UNK vô tình trở thành từ xuất hiện nhiều nhất, dẫn đến xác suất sinh ra UNK tại các trạng thái trở nên lớn hơn.\n",
        "\n",
        "# 2. Các câu có xác suất thấp nhất\n",
        "10 câu có xác suất thấp nhất đều là các câu rất dài (50–70+ từ), và chứa nhiều UNK cùng cấu trúc phức tạp.\n",
        "\n",
        "Đây cũng là kết quả của hiện tượng thiên vị về độ dài, khi các từ có độ dài càng cao thì số lượng phép nhân cho số bé hơn 1 càng nhiều, dẫn đến giá trị xác suất trở nên rất bé.\n",
        "\n",
        "Bên cạnh đó các câu này còn có cấu trúc ngữ pháp phức tạp hơn, khiến cho ma trận chuyển tiếp A chứa các giá trị chuyển trạng thái rất nhỏ khi gặp cấu trúc này.\n",
        "\n",
        "# 3. Giá trị xác suất quá nhỏ\n",
        "Đối với tập dữ liệu hiện tại, các câu có độ dài không quá lớn khiến cho giá trị xác suất không bị bé vượt ngưỡng e-324 của kiểu float64 mà numpy đang sử dụng. Nhưng với giải thuật hiện tại, nếu gặp câu có độ dài lớn hơn nhiều sẽ rất dễ gặp hiện tượng tràn số dưới dẫn đến giá trị xác suất trả về là 0.0. Để giải quyết cho hiện tượng trên, ta hoàn toàn có thể chuyển bài toán sang không gian logagite Bằng cách này, phép nhân xác suất (ví dụ: $P_1 \\times P_2$) được chuyển đổi thành phép cộng log-probability (ví dụ: $\\log(P_1) + \\log(P_2)$), giúp tránh các giá trị bị làm tròn về 0. Khi cần thực hiện phép cộng trong không gian log, kỹ thuật \"Log-Sum-Exp\" sẽ được sử dụng để đảm bảo tính toán luôn ổn định.\n",
        "\n"
      ],
      "metadata": {
        "id": "B1kD0n5jQ302"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Hàm chuyển câu văn bản thành chuỗi chỉ số (Indices)\n",
        "def sentence_to_indices(sentence_str, word2id, unk_token=\"<UNK>\"):\n",
        "    words = sentence_str.strip().split()\n",
        "    idx_unk = word2id[unk_token]\n",
        "\n",
        "    indices = []\n",
        "    for w in words:\n",
        "        indices.append(word2id.get(w, idx_unk))\n",
        "\n",
        "    return np.array(indices), words\n",
        "\n",
        "def compare_two_sentences(sent1, sent2, pi, A, B, word2id, forward_func):\n",
        "    idx1, words1 = sentence_to_indices(sent1, word2id)\n",
        "    idx2, words2 = sentence_to_indices(sent2, word2id)\n",
        "\n",
        "    prob1 = forward_func(idx1, pi, A, B)\n",
        "    prob2 = forward_func(idx2, pi, A, B)\n",
        "\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"1. \\\"{sent1}\\\" -> {prob1:.5e}\")\n",
        "    print(f\"2. \\\"{sent2}\\\" -> {prob2:.5e}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    if prob1 == 0 or prob2 == 0:\n",
        "        print(\"Một trong hai câu có xác suất bằng 0 (hoặc quá nhỏ bị làm tròn).\")\n",
        "    else:\n",
        "        if prob1 > prob2:\n",
        "            ratio = prob1 / prob2\n",
        "            print(f\"Câu \\\"{sent1}\\\" có xác suất cao hơn câu \\\"{sent2}\\\" gấp {ratio:,.2f} lần.\")\n",
        "            print(f\"=> Câu \\\"{sent1}\\\" được mô hình đánh giá là hợp lý hơn.\")\n",
        "        else:\n",
        "            ratio = prob2 / prob1\n",
        "            print(f\"Câu \\\"{sent2}\\\" có xác suất cao hơn câu \\\"{sent1}\\\" gấp {ratio:,.2f} lần.\")\n",
        "            print(f\"=> Câu \\\"{sent2}\\\" được mô hình đánh giá là hợp lý hơn.\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "sentence_a = \"I love you\"\n",
        "sentence_b = \"Love you I\"\n",
        "\n",
        "print(\"\\nKIỂM TRA ĐỘ LỆCH XÁC SUẤT (Cặp 1):\")\n",
        "compare_two_sentences(sentence_a, sentence_b, pi, A, B, word2id, forward_algorithm)\n",
        "\n",
        "sentence_c = \"He is a good student\"\n",
        "sentence_d = \"He is a good the\"\n",
        "\n",
        "print(\"\\nKIỂM TRA ĐỘ LỆCH XÁC SUẤT (Cặp 2):\")\n",
        "compare_two_sentences(sentence_c, sentence_d, pi, A, B, word2id, forward_algorithm)"
      ],
      "metadata": {
        "id": "QvXllXn4RJwh",
        "outputId": "e07c43d4-a01f-4766-ad16-c66cdc41ec1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "KIỂM TRA ĐỘ LỆCH XÁC SUẤT (Cặp 1):\n",
            "------------------------------------------------------------\n",
            "1. \"I love you\" -> 3.88748e-10\n",
            "2. \"Love you I\" -> 3.00968e-14\n",
            "------------------------------------------------------------\n",
            "Câu \"I love you\" có xác suất cao hơn câu \"Love you I\" gấp 12,916.58 lần.\n",
            "=> Câu \"I love you\" được mô hình đánh giá là hợp lý hơn.\n",
            "------------------------------------------------------------\n",
            "\n",
            "KIỂM TRA ĐỘ LỆCH XÁC SUẤT (Cặp 2):\n",
            "------------------------------------------------------------\n",
            "1. \"He is a good student\" -> 1.23059e-12\n",
            "2. \"He is a good the\" -> 1.90686e-11\n",
            "------------------------------------------------------------\n",
            "Câu \"He is a good the\" có xác suất cao hơn câu \"He is a good student\" gấp 15.50 lần.\n",
            "=> Câu \"He is a good the\" được mô hình đánh giá là hợp lý hơn.\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Có sự mâu thuẫn ở cặp câu thứ 2 khi cặp đúng ngữ pháp trong thực tế hơn lại có xác suất nhỏ hơn trong mô hình. Điều này được giải thích do xác suất phát xạ."
      ],
      "metadata": {
        "id": "_yCz3adnrTgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_emission_bias(word2id, tag2id, B, word_check):\n",
        "    if word_check not in word2id:\n",
        "        print(f\"Từ '{word_check}' không có trong từ điển (sẽ bị tính là UNK)\")\n",
        "        return\n",
        "\n",
        "    w_idx = word2id[word_check]\n",
        "\n",
        "    best_tag_idx = np.argmax(B[:, w_idx])\n",
        "    best_prob = B[best_tag_idx, w_idx]\n",
        "\n",
        "    id2tag = {i: t for t, i in tag2id.items()}\n",
        "    best_tag = id2tag[best_tag_idx]\n",
        "\n",
        "    print(f\"Từ '{word_check}':\")\n",
        "    print(f\" - Nhãn phổ biến nhất: {best_tag}\")\n",
        "    print(f\" - Xác suất phát xạ - P('{word_check}'|{best_tag}): {best_prob:.5f}\")\n",
        "\n",
        "print(\"--- SO SÁNH XÁC SUẤT TỪ VỰNG ---\")\n",
        "check_emission_bias(word2id, tag2id, B, \"the\")\n",
        "check_emission_bias(word2id, tag2id, B, \"student\")"
      ],
      "metadata": {
        "id": "J7g2mYyoR7y_",
        "outputId": "4de61ce3-5d18-4e5c-992b-c832b1853e0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- SO SÁNH XÁC SUẤT TỪ VỰNG ---\n",
            "Từ 'the':\n",
            " - Nhãn phổ biến nhất: DT\n",
            " - Xác suất phát xạ - P('the'|DT): 0.50150\n",
            "Từ 'student':\n",
            " - Nhãn phổ biến nhất: NN\n",
            " - Xác suất phát xạ - P('student'|NN): 0.00028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kết quả\n",
        "Mô hình HMM giải thích khá tốt về cấu trúc ngữ pháp cho câu, khi với độ dài nhất định, một câu có xác suất xảy ra cao hơn thì sẽ có cấu trúc ngữ pháp phù hợp hơn trong mô hình đang xét. Tuy nhiên, mô hình vẫn còn rất nhiều hạn chế như cách xử lý các từ hiểm quá thô sơ hay hiện tượng thiên vị độ dài.\n",
        "\n",
        "Ta có thể hạn chế được điểm yếu trên bằng cách sử dụng chuẩn hóa xác suất của một chuỗi quan sát bằng cách chia cho độ dài câu. Hay cải tiến cách xử lý từ hiếm bằng phương pháp Subword Tokenization.\n",
        "\n",
        "Với mô hình HMM hiện tại còn gặp hiện tượng thiên vị tần suất từ. Do sự chênh lệch quá lớn trong Xác suất Phát xạ giữa từ phổ biến và từ hiếm, mô hình có xu hướng ưu tiên các câu chứa từ thông dụng hơn là các câu đúng cấu trúc ngữ pháp nhưng chứa từ ít gặp.\n",
        "\n",
        "Sử dụng các phương pháp làm mịn nâng cao (như Good-Turing hoặc Witten-Bell) thay vì Laplace đơn giản để ước lượng tốt hơn xác suất cho các từ hiếm (Rare words) và từ chưa biết (OOV).\n",
        "\n",
        "Hoặc đơn giản hơn, ta sử dụng các mô hình hiện đại hơn và thông minh hơn trong việc xử lý chuỗi chẳng hạn như mạng Neuron."
      ],
      "metadata": {
        "id": "aW2ic6K3RU3x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Giải thuật Viterbi\n",
        "## Giới thiệu các nhãn POS (Penn Treebank)\n",
        "\n",
        "Trong bài này, em dataset nhóm sử dụng bộ nhãn POS theo chuẩn **Penn Treebank**. Dưới đây là một số nhãn thường gặp:\n",
        "\n",
        "### 1. Danh từ (Nouns)\n",
        "\n",
        "| Tag   | Ý nghĩa                               | Ví dụ                        |\n",
        "|-------|---------------------------------------|------------------------------|\n",
        "| **NN**   | Danh từ thường, số ít                  | dog, house, book             |\n",
        "| **NNS**  | Danh từ thường, số nhiều               | dogs, houses, books          |\n",
        "| **NNP**  | Danh từ riêng, số ít                   | John, London, Tuesday        |\n",
        "| **NNPS** | Danh từ riêng, số nhiều                | Americans, Europeans         |\n",
        "\n",
        "### 2. Động từ (Verbs)\n",
        "\n",
        "| Tag   | Ý nghĩa                                             | Ví dụ                              |\n",
        "|-------|-----------------------------------------------------|------------------------------------|\n",
        "| **VB**   | Động từ nguyên mẫu                                | eat, go, run                       |\n",
        "| **VBD**  | Động từ quá khứ                                  | ate, went, ran                     |\n",
        "| **VBG**  | Hiện tại phân từ / V-ing                         | eating, going, running            |\n",
        "| **VBN**  | Quá khứ phân từ                                  | eaten, gone, broken               |\n",
        "| **VBP**  | Hiện tại, không ngôi thứ 3 số ít                 | I eat, you go                      |\n",
        "| **VBZ**  | Hiện tại, ngôi thứ 3 số ít                       | he eats, she goes                 |\n",
        "\n",
        "### 3. Tính từ & Trạng từ\n",
        "\n",
        "| Tag   | Ý nghĩa                         | Ví dụ                         |\n",
        "|-------|---------------------------------|-------------------------------|\n",
        "| **JJ**   | Tính từ                         | big, small, happy             |\n",
        "| **JJR**  | Tính từ so sánh hơn             | bigger, smaller, happier      |\n",
        "| **JJS**  | Tính từ so sánh nhất            | biggest, smallest, happiest   |\n",
        "| **RB**   | Trạng từ                        | quickly, very, well           |\n",
        "| **RBR**  | Trạng từ so sánh hơn            | faster, better                |\n",
        "| **RBS**  | Trạng từ so sánh nhất           | fastest, best                 |\n",
        "\n",
        "### 4. Đại từ, mạo từ, giới từ, liên từ\n",
        "\n",
        "| Tag    | Ý nghĩa                           | Ví dụ                         |\n",
        "|--------|-----------------------------------|--------------------------------|\n",
        "| **PRP**   | Đại từ nhân xưng                  | I, you, he, she, they          |\n",
        "| **PRP$**  | Đại từ sở hữu                     | my, your, his, her             |\n",
        "| **DT**    | Mạo từ / từ hạn định              | a, an, the, this, those        |\n",
        "| **IN**    | Giới từ / liên từ phụ thuộc       | in, on, at, of, because, if    |\n",
        "| **CC**    | Liên từ đẳng lập                  | and, or, but                   |\n",
        "| **TO**    | Từ *to* (trước động từ nguyên mẫu) | to go, to eat                  |\n",
        "\n",
        "### 5. Một số nhãn khác\n",
        "\n",
        "| Tag   | Ý nghĩa                     | Ví dụ                       |\n",
        "|-------|-----------------------------|-----------------------------|\n",
        "| **MD**   | Trợ động từ khuyết thiếu    | can, will, must, should     |\n",
        "| **CD**   | Số từ                      |  10, 20       |\n",
        "| **UH**   | Thán từ                    | oh,              |\n",
        "| **. , : ; ? !** | Dấu câu            | . , : ; ? !                 |\n",
        "\n",
        "Trong mô hình HMM, các nhãn POS ở trên chính là **trạng thái ẩn**, còn các từ trong câu là **chuỗi quan sát**. Nhiệm vụ của mô hình là, với mỗi câu đầu vào, tìm ra chuỗi nhãn POS phù hợp nhất cho từng từ.\n"
      ],
      "metadata": {
        "id": "k2IDLzZRzNFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "states = tag_set\n",
        "\n",
        "# Chuyển pi, A, B từ array sang dict mà hàm viterbi cần\n",
        "start_p = {\n",
        "    tag: float(pi[i])\n",
        "    for i, tag in enumerate(tag_set)\n",
        "}\n",
        "\n",
        "trans_p = {\n",
        "    tag_i: {\n",
        "        tag_j: float(A[i, j])\n",
        "        for j, tag_j in enumerate(tag_set)\n",
        "    }\n",
        "    for i, tag_i in enumerate(tag_set)\n",
        "}\n",
        "\n",
        "emit_p = {\n",
        "    tag_i: {\n",
        "        word: float(B[i, w])\n",
        "        for w, word in enumerate(vocab)\n",
        "    }\n",
        "    for i, tag_i in enumerate(tag_set)\n",
        "}"
      ],
      "metadata": {
        "id": "4q30LI_Zf6UI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from modules.viterbi_algorithm import *\n",
        "test_words = X_dev[1]\n",
        "gold_tags  = Y_dev[1]\n",
        "\n",
        "pred_tags, prob = viterbi_algorithm(test_words, states, start_p, trans_p, emit_p)\n",
        "\n",
        "print(\"Câu test:\")\n",
        "print(test_words)\n",
        "print(\"\\nNhãn dự đoán:\")\n",
        "print(pred_tags)\n",
        "print(\"\\nNhãn gold:\")\n",
        "print(gold_tags)\n",
        "print(\"\\nXác suất:\", prob)"
      ],
      "metadata": {
        "id": "TO1pyqOTgFhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ed9WSxpaZpW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_sent1 = [\"he\", \"loves\" \"this\", \"subject\", \"the\", \"most\"]\n",
        "test_words1 = map_unk(raw_sent1)\n",
        "\n",
        "pred_tags1, prob1 = viterbi_algorithm(test_words1, states, start_p, trans_p, emit_p)\n",
        "\n",
        "print(\"Câu gốc:\", raw_sent1)\n",
        "print(\"Câu sau khi map UNK:\", test_words1)\n",
        "print(\"Nhãn dự đoán:\", pred_tags1)\n",
        "print(\"Xác suất:\", prob1)\n",
        "\n",
        "raw_sent2 = [\"he\", \"is\", \"doing\", \"machine\", \"learning\", \"assignment\"]\n",
        "test_words2 = map_unk(raw_sent2)\n",
        "\n",
        "pred_tags2, prob2 = viterbi_algorithm(test_words2, states, start_p, trans_p, emit_p)\n",
        "\n",
        "print(\"Câu gốc:\", raw_sent2)\n",
        "print(\"Câu sau khi map UNK:\", test_words2)\n",
        "print(\"Nhãn dự đoán:\", pred_tags2)\n",
        "print(\"Xác suất:\", prob2)"
      ],
      "metadata": {
        "id": "e0YpqlQngRJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Khi thử một số câu tự tạo như:\n",
        "\n",
        "- \"he love this subject the most\"\n",
        "- \"he is doing machine learning assignment\"\n",
        "\n",
        "mô hình gán nhãn khá hợp lý: phân biệt đúng các đại từ (PRP), động từ chia theo chủ ngữ (VBZ), dạng V-ing (VBG), mạo từ (DT), trạng từ so sánh nhất (RBS).\n",
        "\n",
        "Các lỗi chủ yếu xuất hiện ở những cụm mơ hồ như \"machine learning\", nơi từ *learning* vừa có thể được gán là danh từ (NN) vừa có thể là động từ dạng V-ing (VBG). Đây là kiểu mơ hồ thường gặp của mô hình HMM sử dụng ngữ cảnh ngắn.\n"
      ],
      "metadata": {
        "id": "AQagqFH-_vko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_correct = 0\n",
        "total_tokens  = 0\n",
        "\n",
        "for words, gold in zip(X_dev, Y_dev):\n",
        "    pred, _ = viterbi_algorithm(words, states, start_p, trans_p, emit_p)\n",
        "    # đếm đúng / sai cho câu này\n",
        "    for p, g in zip(pred, gold):\n",
        "        if p == g:\n",
        "            total_correct += 1\n",
        "        total_tokens += 1\n",
        "\n",
        "overall_acc = total_correct / total_tokens\n",
        "print(\"Accuracy toàn dev set:\", overall_acc)"
      ],
      "metadata": {
        "id": "NgPV2QGa0joI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Nhận xét kết quả**\n",
        "\n",
        "Đoạn code trên tính **độ chính xác (accuracy)** trên tập dev theo công thức:\n",
        "\n",
        "$$\n",
        "\\text{accuracy} = \\frac{\\text{số token gán đúng nhãn}}{\\text{tổng số token}}\n",
        "$$\n",
        "\n",
        "Kết quả thu được:\n",
        "\n",
        "- **Accuracy trên dev ≈ 0.9482 (≈ 94.8%)**\n",
        "\n",
        "Như vậy, với một mô hình HMM rất cơ bản (ước lượng tham số bằng đếm tần suất có smoothing, dùng token `<UNK>` cho từ hiếm) và thuật toán Viterbi, hệ thống đã gán đúng POS cho gần **95% số từ** trong tập kiểm tra. Đây là một kết quả khá tốt đối với HMM thuần túy, cho thấy mô hình đã học được phân bố:\n",
        "\n",
        "- xác suất bắt đầu câu với từng nhãn,\n",
        "- xác suất chuyển tiếp giữa các nhãn (A),\n",
        "- xác suất phát xạ từ ứng với từng nhãn (B).\n",
        "\n",
        "Phần **~5% còn lại** chủ yếu rơi vào các trường hợp mơ hồ về từ loại, ví dụ những từ vừa có thể là danh từ vừa có thể là động từ/tính từ, hoặc các từ ít xuất hiện trong tập huấn luyện. Đây là giới hạn tự nhiên của HMM bậc 1 chỉ dùng thông tin ngữ cảnh rất ngắn (tag ngay trước), chưa tận dụng được ngữ cảnh xa hay thông tin hình thái (suffix, viết hoa, v.v.).\n",
        "\n",
        "Trong các hướng phát triển tiếp theo, có thể cải thiện bằng cách:\n",
        "- thêm đặc trưng cho từ mới (đuôi `-ing`, `-ed`, số nhiều `-s`, chữ hoa…),\n",
        "- dùng mô hình mạnh hơn như BiLSTM-CRF hoặc Transformer-based tagger,"
      ],
      "metadata": {
        "id": "98bDPNqJ-SRo"
      }
    }
  ]
}